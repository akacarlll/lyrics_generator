{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlf\\anaconda3\\envs\\lyrics_genius\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(r\"C:\\Users\\carlf\\Documents\\GitHub\\lyrics_generator\\data\\05_lyrics_genius_\\lyrics_genius.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Lyrics', 'Artist'], dtype='object') (857, 2)\n"
     ]
    }
   ],
   "source": [
    "df = data.query(\"Artist == 'BOOBA'| Artist == 'La Fouine'\")\n",
    "df = df[[\"Lyrics\", \"Artist\"]]\n",
    "print(df.columns,\n",
    "    df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(845, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"Lyrics\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_classify = [\"BOOBA\", \"La Fouine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les labels\n",
    "df['Label'] = df['Artist'].apply(lambda x: artists_to_classify.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser en ensembles d'entraînement et de test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['Lyrics'].tolist(),\n",
    "    df['Label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['Label'],  # Utiliser les labels pour stratifier\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: {0: 350, 1: 326}\n",
      "Test distribution: {0: 87, 1: 82}\n",
      "Class 0: Train ratio: 0.52, Test ratio: 0.51\n",
      "Class 1: Train ratio: 0.48, Test ratio: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Calculer les proportions dans les ensembles d'entraînement et de test\n",
    "import numpy as np\n",
    "\n",
    "train_distribution = np.unique(train_labels, return_counts=True)\n",
    "test_distribution = np.unique(test_labels, return_counts=True)\n",
    "\n",
    "print(\"Train distribution:\", dict(zip(train_distribution[0], train_distribution[1])))\n",
    "print(\"Test distribution:\", dict(zip(test_distribution[0], test_distribution[1])))\n",
    "\n",
    "# Vérifiez si les proportions sont similaires\n",
    "total_train = sum(train_distribution[1])\n",
    "total_test = sum(test_distribution[1])\n",
    "\n",
    "for cls, count in zip(train_distribution[0], train_distribution[1]):\n",
    "    train_ratio = count / total_train\n",
    "    test_ratio = dict(zip(test_distribution[0], test_distribution[1]))[cls] / total_test\n",
    "    print(f\"Class {cls}: Train ratio: {train_ratio:.2f}, Test ratio: {test_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlf\\anaconda3\\envs\\lyrics_genius\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\carlf\\.cache\\huggingface\\hub\\models--camembert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "All PyTorch model weights were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFCamembertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Charger le tokenizer et le modèle\n",
    "\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "model_name = \"camembert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokeniser les données\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en Dataset TensorFlow\n",
    "def to_tf_dataset(encodings, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings), labels))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = to_tf_dataset(train_encodings, train_labels).shuffle(1000).batch(16)\n",
    "test_dataset = to_tf_dataset(test_encodings, test_labels).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler et entraîner le modèle\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "43/43 [==============================] - 899s 19s/step - loss: 0.6692 - accuracy: 0.5902 - val_loss: 0.6430 - val_accuracy: 0.6331\n",
      "Epoch 2/3\n",
      "43/43 [==============================] - 1378s 29s/step - loss: 0.5072 - accuracy: 0.7589 - val_loss: 0.4634 - val_accuracy: 0.7870\n",
      "Epoch 3/3\n",
      "43/43 [==============================] - 1058s 25s/step - loss: 0.3274 - accuracy: 0.8728 - val_loss: 0.5059 - val_accuracy: 0.8107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x209809c6ff0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=test_dataset, \n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 78s 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "predictions = model.predict(test_dataset).logits\n",
    "predicted_labels = tf.argmax(predictions, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "\n",
    "Scoring de la classification en utilisant CamemBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BOOBA       0.94      0.68      0.79        87\n",
      "   La Fouine       0.74      0.95      0.83        82\n",
      "\n",
      "    accuracy                           0.81       169\n",
      "   macro avg       0.84      0.81      0.81       169\n",
      "weighted avg       0.84      0.81      0.81       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels, target_names=artists_to_classify))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat\n",
    "\n",
    "Scoring de la classification en utilisant DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BOOBA       0.82      0.88      0.85        88\n",
      "   La Fouine       0.85      0.79      0.82        81\n",
      "\n",
      "    accuracy                           0.83       169\n",
      "   macro avg       0.84      0.83      0.83       169\n",
      "weighted avg       0.84      0.83      0.83       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels, target_names=artists_to_classify))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyrics_genius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
